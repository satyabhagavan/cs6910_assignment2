{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, Subset\nimport numpy as np\nfrom sklearn.utils import shuffle # for shuffling\nimport os\nimport cv2\nimport random\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-07T07:16:42.162884Z","iopub.execute_input":"2024-04-07T07:16:42.163249Z","iopub.status.idle":"2024-04-07T07:16:51.378564Z","shell.execute_reply.started":"2024-04-07T07:16:42.163221Z","shell.execute_reply":"2024-04-07T07:16:51.377779Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# class labels\nclassesList = [\"Amphibia\", \"Animalia\", \"Arachnida\", \"Aves\", \"Fungi\", \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:16:51.380023Z","iopub.execute_input":"2024-04-07T07:16:51.380422Z","iopub.status.idle":"2024-04-07T07:16:51.384867Z","shell.execute_reply.started":"2024-04-07T07:16:51.380396Z","shell.execute_reply":"2024-04-07T07:16:51.383851Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip -O nature_12K.zip\n!unzip -q nature_12K.zip\n!rm nature_12K.zip","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:16:51.386216Z","iopub.execute_input":"2024-04-07T07:16:51.386567Z","iopub.status.idle":"2024-04-07T07:17:36.933003Z","shell.execute_reply.started":"2024-04-07T07:16:51.386527Z","shell.execute_reply":"2024-04-07T07:17:36.931719Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2024-04-07 07:16:52--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.207, 142.250.125.207, 142.250.136.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3816687935 (3.6G) [application/zip]\nSaving to: 'nature_12K.zip'\n\nnature_12K.zip      100%[===================>]   3.55G   244MB/s    in 15s     \n\n2024-04-07 07:17:07 (242 MB/s) - 'nature_12K.zip' saved [3816687935/3816687935]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"dtype = torch.float\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:36.935724Z","iopub.execute_input":"2024-04-07T07:17:36.936056Z","iopub.status.idle":"2024-04-07T07:17:36.994073Z","shell.execute_reply.started":"2024-04-07T07:17:36.936025Z","shell.execute_reply":"2024-04-07T07:17:36.993092Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Loading pretrained ResNet50 model\nmodel = models.resnet50(pretrained=True)\n\n# Freezing all the parameters in the model\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Getting the number of inputs for the final layer\nnum_features = model.fc.in_features  \nmodel.fc = nn.Linear(num_features, 10) ","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:36.995455Z","iopub.execute_input":"2024-04-07T07:17:36.995755Z","iopub.status.idle":"2024-04-07T07:17:38.470421Z","shell.execute_reply.started":"2024-04-07T07:17:36.995731Z","shell.execute_reply":"2024-04-07T07:17:38.469440Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 155MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n# !wandb login\nwandb.login()\n# login into your wandb account","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:38.471713Z","iopub.execute_input":"2024-04-07T07:17:38.472008Z","iopub.status.idle":"2024-04-07T07:17:40.917117Z","shell.execute_reply.started":"2024-04-07T07:17:38.471984Z","shell.execute_reply":"2024-04-07T07:17:40.916114Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# resnet50 takes input dimension of 224*224\nresize_width = 224\nresize_height = 224","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:40.918298Z","iopub.execute_input":"2024-04-07T07:17:40.918727Z","iopub.status.idle":"2024-04-07T07:17:40.922852Z","shell.execute_reply.started":"2024-04-07T07:17:40.918701Z","shell.execute_reply":"2024-04-07T07:17:40.921946Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def load_data(train_dir, test_dir, batchSize):\n    \n    # Transformation\n    transform = transforms.Compose([\n        transforms.Resize((resize_width, resize_height)), # Resizing the image\n        transforms.ToTensor(), # Converting image to tensor\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\n    ])\n\n    # Dataset\n    TrainDataset = datasets.ImageFolder(root=train_dir, transform=transform)\n    class_to_idx = TrainDataset.class_to_idx\n\n    # Initialize lists to hold indices for training and validation\n    train_indices = []\n    val_indices = []\n\n    # Spliting indices for each class\n    for class_name, class_index in class_to_idx.items():\n        # Find indices of images in the current class\n        class_indices = [i for i, (_, label) in enumerate(TrainDataset.samples) if label == class_index]\n        # Split these indices into training and validation\n        _train_indices, _val_indices = train_test_split(class_indices, test_size=0.2, random_state=42)\n        # Append to the main list\n        train_indices.extend(_train_indices)\n        val_indices.extend(_val_indices)\n\n    # creating subsets for training and validation\n    # based on the indices we took from splitting \n    train_subset = Subset(TrainDataset, train_indices)\n    val_subset = Subset(TrainDataset, val_indices)\n\n    # Create data loaders\n    trainData_loader = DataLoader(train_subset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=True)\n    valData_loader = DataLoader(val_subset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=True)\n\n    TestDataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    # DataLoader with shuffling\n    TestData_loader = DataLoader(TestDataset,num_workers=2, batch_size=batchSize, pin_memory=True)\n    \n    return trainData_loader, valData_loader, TestData_loader\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:40.925169Z","iopub.execute_input":"2024-04-07T07:17:40.925440Z","iopub.status.idle":"2024-04-07T07:17:42.019582Z","shell.execute_reply.started":"2024-04-07T07:17:40.925416Z","shell.execute_reply":"2024-04-07T07:17:42.018581Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\ndef train(model, criterion, optimizer, num_epochs, train_loader, val_loader):\n    for epoch in range(num_epochs):\n        # activating the model in train mode\n        model.train()\n        \n        for ind, (inputs, labels) in enumerate(tqdm(train_loader, desc=f'Training Progress {epoch+1}')):\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        find_accuracy(model, criterion, train_loader, \"train\")\n        find_accuracy(model, criterion, val_loader, \"validation\")\n        \n\ndef find_accuracy(model, criterion, dataLoader, dataName):\n#     making the model in evaluation mode\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in dataLoader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            val_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    print(f'{dataName} Loss: {val_loss/len(dataLoader)}, '\n          f'{dataName} Accuracy: {100*correct/total}%\\n')\n    wandb.log({f\"{dataName}_loss\": val_loss/len(dataLoader)})\n    wandb.log({f\"{dataName}_accuracy\": 100*correct/total})","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:42.020791Z","iopub.execute_input":"2024-04-07T07:17:42.021068Z","iopub.status.idle":"2024-04-07T07:17:42.035474Z","shell.execute_reply.started":"2024-04-07T07:17:42.021041Z","shell.execute_reply":"2024-04-07T07:17:42.034599Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"trainDataLoader, valDataLoader, testDataLoader = load_data(train_dir = 'inaturalist_12K/train', test_dir = 'inaturalist_12K/val', batchSize = 64)\n\nwandb.init(project=\"Assignment 2\")\nwandb.run.name = \"Training on the pretrained\"\nwandb.run.save()\n\n\noptimizer = optim.NAdam(model.parameters(), lr=1e-4, weight_decay=0.005)\n# Get the number of inputs for the final layer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = torch.nn.DataParallel(model,device_ids = [0]).to(device)\ncriterion = nn.CrossEntropyLoss()\n\n\ntrain(model, criterion, optimizer, 10, trainDataLoader, valDataLoader)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:42.036702Z","iopub.execute_input":"2024-04-07T07:17:42.036950Z","iopub.status.idle":"2024-04-07T07:36:13.815845Z","shell.execute_reply.started":"2024-04-07T07:17:42.036928Z","shell.execute_reply":"2024-04-07T07:36:13.815052Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m065\u001b[0m (\u001b[33mcs23m065_iitm\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_071742-noszqkvr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m065_iitm/Assignment%202/runs/noszqkvr' target=\"_blank\">royal-field-186</a></strong> to <a href='https://wandb.ai/cs23m065_iitm/Assignment%202' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m065_iitm/Assignment%202' target=\"_blank\">https://wandb.ai/cs23m065_iitm/Assignment%202</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m065_iitm/Assignment%202/runs/noszqkvr' target=\"_blank\">https://wandb.ai/cs23m065_iitm/Assignment%202/runs/noszqkvr</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\nTraining Progress 1: 100%|██████████| 125/125 [00:55<00:00,  2.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.6073386850357056, train Accuracy: 62.282785348168524%\n\nvalidation Loss: 1.608281321823597, validation Accuracy: 63.1%\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 2: 100%|██████████| 125/125 [00:45<00:00,  2.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.2542275347709655, train Accuracy: 69.796224528066%\n\nvalidation Loss: 1.2536559738218784, validation Accuracy: 69.65%\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 3: 100%|██████████| 125/125 [00:47<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 1.0778322172164918, train Accuracy: 71.70896362045255%\n\nvalidation Loss: 1.0819353349506855, validation Accuracy: 72.4%\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 4: 100%|██████████| 125/125 [00:45<00:00,  2.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.9797352046966553, train Accuracy: 72.78409801225153%\n\nvalidation Loss: 0.9819287341088057, validation Accuracy: 73.05%\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 5: 100%|██████████| 125/125 [00:46<00:00,  2.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.9199437885284424, train Accuracy: 73.1466433304163%\n\nvalidation Loss: 0.9337042141705751, validation Accuracy: 74.25%\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 6: 100%|██████████| 125/125 [00:46<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.8715750722885132, train Accuracy: 73.9967495936992%\n\nvalidation Loss: 0.88818084821105, validation Accuracy: 74.45%\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 7: 100%|██████████| 125/125 [00:45<00:00,  2.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.8451165175437927, train Accuracy: 74.59682460307539%\n\nvalidation Loss: 0.8616251163184643, validation Accuracy: 74.95%\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 8: 100%|██████████| 125/125 [00:45<00:00,  2.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.8109210572242737, train Accuracy: 75.10938867358419%\n\nvalidation Loss: 0.8354829605668783, validation Accuracy: 75.6%\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 9: 100%|██████████| 125/125 [00:45<00:00,  2.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.787678471326828, train Accuracy: 75.90948868608577%\n\nvalidation Loss: 0.812268789857626, validation Accuracy: 75.5%\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress 10: 100%|██████████| 125/125 [00:44<00:00,  2.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.7618500356674194, train Accuracy: 76.34704338042255%\n\nvalidation Loss: 0.7980984877794981, validation Accuracy: 76.85%\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.050 MB uploaded\\r'), FloatProgress(value=0.027982496545370796, max=1…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▅▆▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▄▆▆▇▇▇▇▇█</td></tr><tr><td>validation_loss</td><td>█▅▃▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>76.34704</td></tr><tr><td>train_loss</td><td>0.76185</td></tr><tr><td>validation_accuracy</td><td>76.85</td></tr><tr><td>validation_loss</td><td>0.7981</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">royal-field-186</strong> at: <a href='https://wandb.ai/cs23m065_iitm/Assignment%202/runs/noszqkvr' target=\"_blank\">https://wandb.ai/cs23m065_iitm/Assignment%202/runs/noszqkvr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240407_071742-noszqkvr/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"# checking top2 accuracy which is a metrix used in the model(top-k in general)\ndef find_top2_accuracy(model, criterion, dataLoader, dataName):\n    model.eval()\n    val_loss = 0.0\n    correct_top1 = 0\n    correct_top2 = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in dataLoader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            val_loss += loss.item()\n\n            # Top-1 accuracy\n            _, predicted_top1 = outputs.max(1)\n            correct_top1 += predicted_top1.eq(labels).sum().item()\n\n            # Top-2 accuracy\n            _, predicted_top2 = outputs.topk(2, 1, True, True)\n            correct_top2 += predicted_top2.eq(labels.view(-1, 1).expand_as(predicted_top2)).sum().item()\n\n            total += labels.size(0)\n    \n    print(f'{dataName} Loss: {val_loss / len(dataLoader)}, '\n          f'{dataName} Top-1 Accuracy: {100 * correct_top1 / total}%, '\n          f'{dataName} Top-2 Accuracy: {100 * correct_top2 / total}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:36:13.817221Z","iopub.execute_input":"2024-04-07T07:36:13.817517Z","iopub.status.idle":"2024-04-07T07:36:13.826496Z","shell.execute_reply.started":"2024-04-07T07:36:13.817486Z","shell.execute_reply":"2024-04-07T07:36:13.825669Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"find_top2_accuracy(model, criterion, testDataLoader, \"test \")","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:36:33.587151Z","iopub.execute_input":"2024-04-07T07:36:33.587509Z","iopub.status.idle":"2024-04-07T07:36:45.864036Z","shell.execute_reply.started":"2024-04-07T07:36:33.587480Z","shell.execute_reply":"2024-04-07T07:36:45.862987Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"test  Loss: 0.7928383331745863, test  Top-1 Accuracy: 75.15%, test  Top-2 Accuracy: 87.5%\n","output_type":"stream"}]},{"cell_type":"code","source":"# for generating the 30 images and their class labels with their predictions\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Identify the computing device used by the model\ncompute_device = next(model.parameters()).device\n\nmodel.eval()  # Switch model to evaluation mode\n\n# Prepare to collect a limited number of image samples for each category\nsamples_limit = 3\ncategory_samples = {category: [] for category in range(10)}  # Assuming categories are labeled 0-9\n\n# Ensure no gradient computations for efficiency\nwith torch.no_grad():\n    for batch_images, batch_labels in testDataLoader:\n        batch_images, batch_labels = batch_images.to(compute_device), batch_labels.to(compute_device)  # Match model's device\n        # Check if sufficient samples have been collected\n        if all(len(samples) >= samples_limit for samples in category_samples.values()):\n            break\n        for image, label in zip(batch_images, batch_labels):\n            current_label = label.item()\n            if len(category_samples[current_label]) < samples_limit:\n                # Predict the label for each image\n                prediction = model(image.unsqueeze(0)).argmax(1).item()\n                # Store the CPU-based image and its predicted label\n                category_samples[current_label].append((image.cpu(), prediction))\n\n# Setting up the visualization\nfigure, axes = plt.subplots(10, 3, figsize=(10, 33))  # Allocate a grid for the sample images\n\nfor category_id, images in category_samples.items():\n    for index, (image, predicted) in enumerate(images):\n        plot_axis = axes[category_id, index]\n        # Reformat image for plotting\n        image_to_plot = image.numpy().transpose((1, 2, 0))\n        normalize_mean = np.array([0.485, 0.456, 0.406])\n        normalize_std = np.array([0.229, 0.224, 0.225])\n        image_to_plot = normalize_std * image_to_plot + normalize_mean\n        image_to_plot = np.clip(image_to_plot, 0, 1)\n        plot_axis.imshow(image_to_plot)\n        plot_axis.set_title(f'Real: {classesList[category_id]}, Guess: {classesList[predicted]}')\n        plot_axis.axis('off')\n\nplt.tight_layout()\n\n# Save and display the image grid\nplt.savefig('/kaggle/working/predictions_overview.png', dpi=300)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T23:55:31.092925Z","iopub.execute_input":"2024-04-05T23:55:31.093900Z","iopub.status.idle":"2024-04-05T23:55:54.658753Z","shell.execute_reply.started":"2024-04-05T23:55:31.093861Z","shell.execute_reply":"2024-04-05T23:55:54.657426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for generating the confusion matrix\nimport torch\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nmodel.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for data, labels in testDataLoader:\n        data = data.to(device)\n        outputs = model(data)\n        \n        _, predicted = torch.max(outputs, 1)\n        \n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Compute the confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\n\n# Plotting the confusion matrix\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues', xticklabels=classesList, yticklabels=classesList)\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T23:55:54.661892Z","iopub.execute_input":"2024-04-05T23:55:54.662873Z","iopub.status.idle":"2024-04-05T23:56:09.447142Z","shell.execute_reply.started":"2024-04-05T23:55:54.662818Z","shell.execute_reply":"2024-04-05T23:56:09.446123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}